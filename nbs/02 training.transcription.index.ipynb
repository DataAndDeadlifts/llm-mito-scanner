{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp training.transcription.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jdb/projects/llm-mito-scanner/venv/lib/python3.10/site-packages/Bio/__init__.py:138: BiopythonWarning: You may be importing Biopython from inside the source tree. This is bad practice and might lead to downstream issues. In particular, you might encounter ImportErrors due to missing compiled C extensions. We recommend that you try running your code from outside the source tree. If you are outside the source tree then you have a setup.py file in an unexpected directory: /home/jdb/projects/llm-mito-scanner/venv/lib/python3.10/site-packages\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "from torchtext.vocab import vocab, Vocab\n",
    "from collections import Counter, OrderedDict\n",
    "from multiprocessing import Pool\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "from llm_mito_scanner.data.download import load_config, \\\n",
    "    get_latest_assembly_path, get_genomic_genbank_path\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "config = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "data_path = Path(config.get(\"data_path\"))\n",
    "data_raw_path = data_path / \"raw\"\n",
    "assemblies_path = data_raw_path / \"assemblies\"\n",
    "latest_assembly_path = get_latest_assembly_path(assemblies_path)\n",
    "genomic_genbank_path = get_genomic_genbank_path(latest_assembly_path)\n",
    "chromosomes_path = latest_assembly_path / \"chromosomes\"\n",
    "training_data_path = latest_assembly_path / \"training\"\n",
    "transcription_data_path = training_data_path / \"transcription\"\n",
    "sequences_data_path = transcription_data_path / \"sequences\"\n",
    "if not sequences_data_path.exists():\n",
    "    raise Exception(f\"This notebook expects the path at {sequences_data_path.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/mnt/e/Data/llm-mito-scanner-data/data/raw/assemblies/GCF_000001405.40_GRCh38.p14/training/transcription/sequences/chromosome=NC_000001.11/partition=0/sequences.parquet'),\n",
       " PosixPath('/mnt/e/Data/llm-mito-scanner-data/data/raw/assemblies/GCF_000001405.40_GRCh38.p14/training/transcription/sequences/chromosome=NC_000001.11/partition=1/sequences.parquet'),\n",
       " PosixPath('/mnt/e/Data/llm-mito-scanner-data/data/raw/assemblies/GCF_000001405.40_GRCh38.p14/training/transcription/sequences/chromosome=NC_000001.11/partition=10/sequences.parquet')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "chromosome_parquet_files = list(sequences_data_path.glob(\"chromosome=*/partition=*/*.parquet\"))\n",
    "chromosome_parquet_files[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "parquet_file_df = pd.DataFrame(chromosome_parquet_files, columns=['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>chromosome</th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/mnt/e/Data/llm-mito-scanner-data/data/raw/ass...</td>\n",
       "      <td>NC_000001.11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/mnt/e/Data/llm-mito-scanner-data/data/raw/ass...</td>\n",
       "      <td>NC_000001.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/mnt/e/Data/llm-mito-scanner-data/data/raw/ass...</td>\n",
       "      <td>NC_000001.11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/mnt/e/Data/llm-mito-scanner-data/data/raw/ass...</td>\n",
       "      <td>NC_000001.11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/mnt/e/Data/llm-mito-scanner-data/data/raw/ass...</td>\n",
       "      <td>NC_000001.11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path    chromosome  partition\n",
       "0  /mnt/e/Data/llm-mito-scanner-data/data/raw/ass...  NC_000001.11          0\n",
       "1  /mnt/e/Data/llm-mito-scanner-data/data/raw/ass...  NC_000001.11          1\n",
       "2  /mnt/e/Data/llm-mito-scanner-data/data/raw/ass...  NC_000001.11          2\n",
       "3  /mnt/e/Data/llm-mito-scanner-data/data/raw/ass...  NC_000001.11          3\n",
       "4  /mnt/e/Data/llm-mito-scanner-data/data/raw/ass...  NC_000001.11          4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "parquet_file_df_path_split = parquet_file_df.path.apply(lambda p: str(p).rsplit(\"/\"))\n",
    "\n",
    "parquet_file_df.loc[:, 'chromosome'] = parquet_file_df_path_split.apply(lambda split_path: split_path[-3].split(\"=\")[-1])\n",
    "parquet_file_df.loc[:, 'partition'] = parquet_file_df_path_split.apply(lambda split_path: int(split_path[-2].split(\"=\")[-1]))\n",
    "parquet_file_df.sort_values(['chromosome', 'partition'], inplace=True)\n",
    "parquet_file_df.reset_index(drop=True, inplace=True)\n",
    "parquet_file_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def index_training_sequence_files(sequences_path: Path) -> pd.DataFrame:\n",
    "    # Index files\n",
    "    chromosome_parquet_files = list(sequences_path.glob(\"chromosome=*/partition=*/*.parquet\"))\n",
    "    parquet_file_df = pd.DataFrame(chromosome_parquet_files, columns=['path'])\n",
    "    # Extract partition info\n",
    "    parquet_file_df_path_split = parquet_file_df.path.apply(lambda p: str(p).rsplit(\"/\"))\n",
    "    parquet_file_df.loc[:, 'chromosome'] = parquet_file_df_path_split.apply(lambda split_path: split_path[-3].split(\"=\")[-1])\n",
    "    parquet_file_df.loc[:, 'partition'] = parquet_file_df_path_split.apply(lambda split_path: int(split_path[-2].split(\"=\")[-1]))\n",
    "    # Sort\n",
    "    parquet_file_df.sort_values(['chromosome', 'partition'], ascending=True, inplace=True)\n",
    "    parquet_file_df.reset_index(drop=True, inplace=True)\n",
    "    return parquet_file_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def make_training_index(index_dir: Path, sequences_path: Path, sample: bool = False, save: bool = False):\n",
    "    sequence_files = index_training_sequence_files(sequences_path)\n",
    "    if sample:\n",
    "        sequence_files = sequence_files.tail(2)\n",
    "    frames = []\n",
    "    for _, row in sequence_files.iterrows():\n",
    "        f_frame = pd.read_parquet(row.path, columns=[\"geneid\", 'transcriptid']).reset_index(drop=False).rename({\"index\": \"file_index\"}, axis=1)\n",
    "        f_frame.loc[:, 'file'] = row.path\n",
    "        f_frame.loc[:, 'chromosome'] = row.chromosome\n",
    "        f_frame.loc[:, 'partition'] = row.partition\n",
    "        frames.append(f_frame)\n",
    "    training_data_index = pd.concat(\n",
    "        frames, \n",
    "        axis=0, ignore_index=True\n",
    "    )\n",
    "    training_data_index.sort_values(['chromosome', 'partition'], ascending=True, inplace=True)\n",
    "    training_data_index.reset_index(drop=True, inplace=True)\n",
    "    if save:\n",
    "        training_data_index.to_csv(index_dir / \"index.csv\", index=False)\n",
    "    return training_data_index\n",
    "\n",
    "\n",
    "def get_training_index(index_dir: Path, sequences_path: Path = None, force: bool = False, **make_kwargs):\n",
    "    index_path = index_dir / \"index.csv\"\n",
    "    if not index_path.exists() or force:\n",
    "        return make_training_index(index_dir, sequences_path, **make_kwargs)\n",
    "    else:\n",
    "        return pd.read_csv(index_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "example_training_data_index = get_training_index(transcription_data_path, sequences_data_path, force=True, save=False, sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_index</th>\n",
       "      <th>geneid</th>\n",
       "      <th>transcriptid</th>\n",
       "      <th>file</th>\n",
       "      <th>chromosome</th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GeneID:55796</td>\n",
       "      <td>NM_001386899.1</td>\n",
       "      <td>/mnt/e/Data/llm-mito-scanner-data/data/raw/ass...</td>\n",
       "      <td>NC_000023.11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>GeneID:55796</td>\n",
       "      <td>NM_001386889.1</td>\n",
       "      <td>/mnt/e/Data/llm-mito-scanner-data/data/raw/ass...</td>\n",
       "      <td>NC_000023.11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>GeneID:55796</td>\n",
       "      <td>NM_001386891.1</td>\n",
       "      <td>/mnt/e/Data/llm-mito-scanner-data/data/raw/ass...</td>\n",
       "      <td>NC_000023.11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>GeneID:55796</td>\n",
       "      <td>NM_001386896.1</td>\n",
       "      <td>/mnt/e/Data/llm-mito-scanner-data/data/raw/ass...</td>\n",
       "      <td>NC_000023.11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>GeneID:55796</td>\n",
       "      <td>NM_018388.4</td>\n",
       "      <td>/mnt/e/Data/llm-mito-scanner-data/data/raw/ass...</td>\n",
       "      <td>NC_000023.11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_index        geneid    transcriptid   \n",
       "0           0  GeneID:55796  NM_001386899.1  \\\n",
       "1           1  GeneID:55796  NM_001386889.1   \n",
       "2           2  GeneID:55796  NM_001386891.1   \n",
       "3           3  GeneID:55796  NM_001386896.1   \n",
       "4           4  GeneID:55796     NM_018388.4   \n",
       "\n",
       "                                                file    chromosome  partition  \n",
       "0  /mnt/e/Data/llm-mito-scanner-data/data/raw/ass...  NC_000023.11          7  \n",
       "1  /mnt/e/Data/llm-mito-scanner-data/data/raw/ass...  NC_000023.11          7  \n",
       "2  /mnt/e/Data/llm-mito-scanner-data/data/raw/ass...  NC_000023.11          7  \n",
       "3  /mnt/e/Data/llm-mito-scanner-data/data/raw/ass...  NC_000023.11          7  \n",
       "4  /mnt/e/Data/llm-mito-scanner-data/data/raw/ass...  NC_000023.11          7  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "example_training_data_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def make_train_test_split(index: pd.DataFrame, random_state = 42):\n",
    "    return train_test_split(index, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "train_idx, test_idx = make_train_test_split(example_training_data_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((983, 6), (328, 6))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "train_idx.shape, test_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_index</th>\n",
       "      <th>geneid</th>\n",
       "      <th>transcriptid</th>\n",
       "      <th>file</th>\n",
       "      <th>chromosome</th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>172</td>\n",
       "      <td>GeneID:7404</td>\n",
       "      <td>XM_011531441.4</td>\n",
       "      <td>/mnt/e/Data/llm-mito-scanner-data/data/raw/ass...</td>\n",
       "      <td>NC_000024.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>708</td>\n",
       "      <td>GeneID:6748</td>\n",
       "      <td>XM_047442389.1</td>\n",
       "      <td>/mnt/e/Data/llm-mito-scanner-data/data/raw/ass...</td>\n",
       "      <td>NC_000023.11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>536</td>\n",
       "      <td>GeneID:266740</td>\n",
       "      <td>NM_001321403.1</td>\n",
       "      <td>/mnt/e/Data/llm-mito-scanner-data/data/raw/ass...</td>\n",
       "      <td>NC_000023.11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>808</td>\n",
       "      <td>GeneID:6901</td>\n",
       "      <td>NM_001303465.2</td>\n",
       "      <td>/mnt/e/Data/llm-mito-scanner-data/data/raw/ass...</td>\n",
       "      <td>NC_000023.11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>682</td>\n",
       "      <td>GeneID:139728</td>\n",
       "      <td>NM_001366976.1</td>\n",
       "      <td>/mnt/e/Data/llm-mito-scanner-data/data/raw/ass...</td>\n",
       "      <td>NC_000023.11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_index         geneid    transcriptid   \n",
       "1117         172    GeneID:7404  XM_011531441.4  \\\n",
       "708          708    GeneID:6748  XM_047442389.1   \n",
       "536          536  GeneID:266740  NM_001321403.1   \n",
       "808          808    GeneID:6901  NM_001303465.2   \n",
       "682          682  GeneID:139728  NM_001366976.1   \n",
       "\n",
       "                                                   file    chromosome   \n",
       "1117  /mnt/e/Data/llm-mito-scanner-data/data/raw/ass...  NC_000024.10  \\\n",
       "708   /mnt/e/Data/llm-mito-scanner-data/data/raw/ass...  NC_000023.11   \n",
       "536   /mnt/e/Data/llm-mito-scanner-data/data/raw/ass...  NC_000023.11   \n",
       "808   /mnt/e/Data/llm-mito-scanner-data/data/raw/ass...  NC_000023.11   \n",
       "682   /mnt/e/Data/llm-mito-scanner-data/data/raw/ass...  NC_000023.11   \n",
       "\n",
       "      partition  \n",
       "1117          0  \n",
       "708           7  \n",
       "536           7  \n",
       "808           7  \n",
       "682           7  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "train_idx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_sequence(file: Path, idx: int) -> pd.Series:\n",
    "    row = pd.read_parquet(file).iloc[idx, :]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "example_sequence = get_sequence(train_idx.iloc[0, -3], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "example_sequence.input.count(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TranscriptionDataset(Dataset):\n",
    "    def __init__(self, training_path: Path, sequences_path: Path, train: bool):\n",
    "        self.training_path = training_path\n",
    "        self.sequences_path = sequences_path\n",
    "        self.train = train\n",
    "        self.training_index = get_training_index(self.training_path, self.sequences_path, sample=False, save=True)\n",
    "        self.train_idx, self.test_idx = make_train_test_split(self.training_index)\n",
    "\n",
    "    def filter_chromosome(self, chromosome: str):\n",
    "        index_chromosomes = self.training_index.chromosome.unique()\n",
    "        if not chromosome in index_chromosomes:\n",
    "            raise ValueError(f\"Chromosome {chromosome} not found in training data.\")\n",
    "        filtered_training_index = self.training_index[self.training_index.chromosome == chromosome]\n",
    "        self.training_index = filtered_training_index\n",
    "        self.train_idx, self.test_idx = make_train_test_split(self.training_index)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        if self.train:\n",
    "            return self.train_idx.shape[0]\n",
    "        else:\n",
    "            return self.test_idx.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx) -> tuple[str, str]:\n",
    "        if self.train:\n",
    "            sequence_row = self.train_idx.iloc[idx, :]\n",
    "        else:\n",
    "            sequence_row = self.test_idx.iloc[idx, :]\n",
    "        sequence = get_sequence(sequence_row.file, sequence_row.file_index)\n",
    "        return sequence.input, sequence.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "transcription_dataset_train = TranscriptionDataset(transcription_data_path, sequences_data_path, True)\n",
    "transcription_dataset_test = TranscriptionDataset(transcription_data_path, sequences_data_path, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97815, 32605)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "len(transcription_dataset_train), len(transcription_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9630, 3211)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "transcription_dataset_train.filter_chromosome(\"NC_000001.11\")\n",
    "transcription_dataset_test.filter_chromosome(\"NC_000001.11\")\n",
    "len(transcription_dataset_train), len(transcription_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13415\n",
      "122052\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "for i, tup in enumerate(transcription_dataset_train):\n",
    "    if i == 2:\n",
    "        break\n",
    "    print(tup[0].count(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def tokenize(seq: str) -> list[str]:\n",
    "    return seq.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "sample_train_data = transcription_dataset_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13416, 13416)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "len(tokenize(sample_train_data[0])), len(tokenize(sample_train_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "gene_path = latest_assembly_path / \"genes\"\n",
    "gene_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'C': 1, 'D': 1})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "Counter(\"C,D\".split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def count_transcription_tokens(parquet_path: Path) -> Counter:\n",
    "    token_counter = Counter()\n",
    "    sequences = pd.read_parquet(parquet_path, columns=['input', 'target'])\n",
    "    input_counter = sum(sequences.input.apply(tokenize).apply(Counter).values.tolist(), Counter())\n",
    "    target_counter = sum(sequences.target.apply(tokenize).apply(Counter).values.tolist(), Counter())\n",
    "    token_counter = input_counter + target_counter\n",
    "    return token_counter\n",
    "\n",
    "\n",
    "UNK_TOKEN = \"<unk>\"\n",
    "PAD_TOKEN = \"<pad>\"\n",
    "BOS_TOKEN = \"<bos>\"\n",
    "EOS_TOKEN = \"<eos>\"\n",
    "SPECIAL_TOKENS = [\n",
    "    UNK_TOKEN,\n",
    "    PAD_TOKEN,\n",
    "    BOS_TOKEN,\n",
    "    EOS_TOKEN\n",
    "]\n",
    "\n",
    "\n",
    "def build_vocab(\n",
    "        parquet_files: list[Path], \n",
    "        special_tokens: list[str] = SPECIAL_TOKENS,\n",
    "        unknown_token: str = UNK_TOKEN):\n",
    "    counter = Counter()\n",
    "    max_processes = min(8, os.cpu_count() - 1)\n",
    "    pool = Pool(\n",
    "        processes=min(max_processes, len(parquet_files)))\n",
    "    try:\n",
    "        pbar = tqdm(total=len(parquet_files), leave=False)\n",
    "        for c in pool.imap_unordered(count_transcription_tokens, parquet_files):\n",
    "            counter = counter + c\n",
    "            pbar.update(1)\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    finally:\n",
    "        pbar.close()\n",
    "        pool.close()\n",
    "    token_ordered_dict = OrderedDict(counter.most_common())\n",
    "    transcription_vocab = vocab(token_ordered_dict, specials=special_tokens, special_first=True)\n",
    "    unk_index = transcription_vocab[unknown_token]\n",
    "    transcription_vocab.set_default_index(unk_index)\n",
    "    return transcription_vocab\n",
    "\n",
    "\n",
    "def get_vocab(\n",
    "        training_path: Path,\n",
    "        force_build: bool = False,\n",
    "        save: bool = True,\n",
    "        **build_vocab_kwargs\n",
    "        ) -> Vocab:\n",
    "    vocab_path = training_path / \"vocab.pt\"\n",
    "    if not vocab_path.exists() or force_build:\n",
    "        transcription_vocab = build_vocab(**build_vocab_kwargs)\n",
    "        if save:\n",
    "            torch.save(transcription_vocab, vocab_path)\n",
    "    else:\n",
    "        transcription_vocab = torch.load(vocab_path)\n",
    "    return transcription_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "example_transcription_vocab = get_vocab(\n",
    "    transcription_data_path, \n",
    "    force_build=True, \n",
    "    save=False,\n",
    "    parquet_files=chromosome_parquet_files[-2:]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "len(example_transcription_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', '<bos>', '<eos>', '<intron>', 'T', 'A', 'G', 'C']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "example_transcription_vocab.lookup_tokens(list(range(0, len(example_transcription_vocab))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def process_training_sequence(sequence: tuple[str, str], data_vocab: Vocab) -> tuple[Tensor, Tensor]:\n",
    "    \"\"\"Converts raw text into a flat Tensor.\"\"\"\n",
    "    input_tensor = torch.tensor(data_vocab(tokenize(sequence[0])), dtype=torch.long)\n",
    "    target_tensor = torch.tensor(data_vocab(tokenize(sequence[1])), dtype=torch.long)\n",
    "    return input_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([7, 5, 7,  ..., 7, 6, 6]), tensor([7, 5, 7,  ..., 7, 6, 6]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "processed_example_sequence = process_training_sequence(sample_train_data, example_transcription_vocab)\n",
    "processed_example_sequence[0], processed_example_sequence[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13416])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "processed_example_sequence[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def batchify_sequence(sequence: Tensor, bsz: int) -> Tensor:\n",
    "    global device\n",
    "    seq_len = sequence.size(0) // bsz\n",
    "    data = sequence[:seq_len * bsz]\n",
    "    data = data.view(bsz, seq_len).t().contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "\n",
    "def batchify(sequence_tensors: tuple[Tensor, Tensor], bsz: int) -> tuple[Tensor, Tensor]:\n",
    "    \"\"\"Divides the data into ``bsz`` separate sequences, removing extra elements\n",
    "    that wouldn't cleanly fit.\n",
    "\n",
    "    Arguments:\n",
    "        data: Tensor, shape ``[N]``\n",
    "        bsz: int, batch size\n",
    "\n",
    "    Returns:\n",
    "        Tensor of shape ``[N // bsz, bsz]``\n",
    "    \"\"\"\n",
    "    input_batches = batchify_sequence(sequence_tensors[0], bsz)\n",
    "    target_batches = batchify_sequence(sequence_tensors[1], bsz)\n",
    "    return input_batches, target_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_batch(input: Tensor, target: Tensor, i: int, bptt: int = 35) -> tuple[Tensor, Tensor]:\n",
    "    global device\n",
    "    seq_len = min(bptt, len(input) - 1 - i)\n",
    "    data = input[i:i+seq_len].to(device)\n",
    "    target = target[i:i+seq_len].to(device)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "bptt = 35\n",
    "eval_batch_size = 10\n",
    "\n",
    "processed_example_sequence_input, processed_example_sequence_target = processed_example_sequence\n",
    "sequences_batch_num = (processed_example_sequence_input.shape[0] - 1) // bptt\n",
    "for batch, i in enumerate(range(0, sequences_batch_num, bptt)):\n",
    "    # Get Batch\n",
    "    data, target = get_batch(processed_example_sequence_input, processed_example_sequence_target, i, bptt)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([7, 5, 7, 8, 7, 7, 6, 7, 5, 5, 5, 7, 7, 8, 5, 7, 8, 5, 8, 8, 7, 7, 7, 7,\n",
       "         5, 5, 6, 7, 8, 6, 7, 7, 5, 7, 6], device='cuda:0'),\n",
       " tensor([7, 5, 7, 8, 7, 7, 6, 7, 5, 5, 5, 7, 7, 8, 5, 7, 8, 5, 8, 8, 7, 7, 7, 7,\n",
       "         5, 5, 6, 7, 8, 6, 7, 7, 5, 7, 6], device='cuda:0'),\n",
       " torch.Size([35]),\n",
       " torch.Size([35]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "print(sequences_batch_num)\n",
    "data, target, data.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
